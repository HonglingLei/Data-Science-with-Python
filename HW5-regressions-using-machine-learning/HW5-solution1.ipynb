{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_steps = 1000\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongling/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n",
      "/Users/hongling/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "dt = pd.read_csv('auto.csv')\n",
    "dt = dt.dropna()\n",
    "iForeign = pd.get_dummies(dt['foreign'])['Foreign']\n",
    "dt.iloc[:,-1] = iForeign\n",
    "\n",
    "def standardize(dt):\n",
    "    mean = np.mean(dt, axis=0)\n",
    "    sd = np.std(dt, axis=0)\n",
    "    return (dt - mean) / sd\n",
    "\n",
    "Y = standardize(dt.iloc[:,2])\n",
    "Y = Y.as_matrix()\n",
    "Y = Y.astype(np.float64)\n",
    "X = standardize(dt.iloc[:,[1,3,4,5,6,7,8,9,10,11]])\n",
    "X.insert(0,'int',1.0)\n",
    "X = X.as_matrix()\n",
    "\n",
    "X=tf.constant(X)\n",
    "Y=tf.constant(Y)\n",
    "epsilon=tf.constant(1e-15)\n",
    "\n",
    "n_samples = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini = np.random.uniform(-10, 10, 11)\n",
    "Beta = tf.Variable(initial_value = ini,name = 'Beta')\n",
    "\n",
    "# Linear Regression.\n",
    "def mean_square(): \n",
    "    return tf.reduce_sum(tf.pow(tf.subtract(Y, tf.tensordot(X,Beta,axes=1)),2))/n_samples\n",
    "\n",
    "# Stochastic Gradient Descent Optimizer.\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "ini = np.random.uniform(-10, 10, 11)\n",
    "Beta = tf.Variable(initial_value = ini, name ='Beta')\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "obj0 = loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 20 loss: 30.985007070914058 change_rate: 0.016268871655499596\n",
      "step: 40 loss: 23.452135015951466 change_rate: 0.012011031264962514\n",
      "step: 60 loss: 18.942986861978465 change_rate: 0.009571949836723216\n",
      "step: 80 loss: 15.886179739637123 change_rate: 0.00813959374879486\n",
      "step: 100 loss: 13.629299986019678 change_rate: 0.007230110713034451\n",
      "step: 120 loss: 11.872456433024167 change_rate: 0.006585498648132288\n",
      "step: 140 loss: 10.460227577019806 change_rate: 0.006080905072902926\n",
      "step: 160 loss: 9.301385196265766 change_rate: 0.005658286731255151\n",
      "step: 180 loss: 8.336431543794243 change_rate: 0.005290770651446184\n",
      "step: 200 loss: 7.523536305718453 change_rate: 0.0049654426956879235\n",
      "step: 220 loss: 6.8318461441995355 change_rate: 0.0046754353987346\n",
      "step: 240 loss: 6.2379277800677455 change_rate: 0.004416409364396618\n",
      "step: 260 loss: 5.723656209900808 change_rate: 0.004185048042592847\n",
      "step: 280 loss: 5.274840516540492 change_rate: 0.00397845470378795\n",
      "step: 300 loss: 4.880269034332891 change_rate: 0.003793941131722281\n",
      "step: 320 loss: 4.531017111202689 change_rate: 0.0036289762754471476\n",
      "step: 340 loss: 4.219931914851285 change_rate: 0.0034811917826954256\n",
      "step: 360 loss: 3.9412427547029396 change_rate: 0.0033484006012027105\n",
      "step: 380 loss: 3.69026327109899 change_rate: 0.0032286118637297645\n",
      "step: 400 loss: 3.463162202743727 change_rate: 0.0031200372492721793\n",
      "step: 420 loss: 3.256785983756501 change_rate: 0.0030210889637144146\n",
      "step: 440 loss: 3.068520831268764 change_rate: 0.002930371203735166\n",
      "step: 460 loss: 2.8961850952587542 change_rate: 0.0028466672662430617\n",
      "step: 480 loss: 2.737944902022481 change_rate: 0.00276892419971094\n",
      "step: 500 loss: 2.592247794702883 change_rate: 0.0026962364601306643\n",
      "step: 520 loss: 2.4577703259930748 change_rate: 0.0026278296053500166\n",
      "step: 540 loss: 2.333376502350959 change_rate: 0.002563044701668735\n",
      "step: 560 loss: 2.2180846951416986 change_rate: 0.002501323840350523\n",
      "step: 580 loss: 2.111041179366454 change_rate: 0.002442196962528801\n",
      "step: 600 loss: 2.011498877161931 change_rate: 0.0023852700547785247\n",
      "step: 620 loss: 1.9188002023714268 change_rate: 0.002330214689730635\n",
      "step: 640 loss: 1.8323631476323077 change_rate: 0.0022767588332711394\n",
      "step: 660 loss: 1.7516699442324586 change_rate: 0.0022246788116800256\n",
      "step: 680 loss: 1.676257770778133 change_rate: 0.002173792320354668\n",
      "step: 700 loss: 1.6057110995767692 change_rate: 0.0021239523547577016\n",
      "step: 720 loss: 1.5396553572327991 change_rate: 0.0020750419496833017\n",
      "step: 740 loss: 1.4777516441152367 change_rate: 0.0020269696219520424\n",
      "step: 760 loss: 1.4196923105334438 change_rate: 0.001979665422396434\n",
      "step: 780 loss: 1.3651972290553385 change_rate: 0.001933077514109159\n",
      "step: 800 loss: 1.3140106350291054 change_rate: 0.0018871692047697937\n",
      "step: 820 loss: 1.265898433029087 change_rate: 0.0018419163708726727\n",
      "step: 840 loss: 1.2206458871817878 change_rate: 0.0017973052207595115\n",
      "step: 860 loss: 1.178055629329735 change_rate: 0.0017533303512879516\n",
      "step: 880 loss: 1.137945931680197 change_rate: 0.0017099930598910443\n",
      "step: 900 loss: 1.1001492006768254 change_rate: 0.0016672998796602512\n",
      "step: 920 loss: 1.0645106568801175 change_rate: 0.0016252613100536477\n",
      "step: 940 loss: 1.0308871720797537 change_rate: 0.001583890719957223\n",
      "step: 960 loss: 0.9991462400259491 change_rate: 0.0015432034032936903\n",
      "step: 980 loss: 0.9691650613224476 change_rate: 0.0015032157701449166\n",
      "step: 1000 loss: 0.9408297263779901 change_rate: 0.0014639446586892436\n"
     ]
    }
   ],
   "source": [
    "# Run training for the given number of steps.\n",
    "for step in range(1, training_steps + 1):\n",
    "    opt_op = optimizer.minimize(loss, var_list = [Beta])\n",
    "    obj = mean_square()\n",
    "    change_rate = float(abs(obj-obj0)/obj0)\n",
    "    obj0 = obj\n",
    "    if step % display_step == 0:\n",
    "        print('step:', step, 'loss:', float(obj), 'change_rate:', change_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
